---
apiVersion: v1
kind: ConfigMap
metadata:
  name: summary.kubernetes.http-events.latency
  namespace: observability-system
  labels:
    purpose: cron-script
data:
  script.pxl: |
    import px

    def _http_events(start_time, end_time, include_health_checks, include_ready_checks, include_unresolved_inbound):
      '''Return DataFrame with selectively filtered data

      Returns a dataframe of http events with health/ready requests filtered out and a failure field added.

      Note this script is prefixed with an underscore and therefore at risk of changing in the future.
      Rely on this function at your own risk.

      Args:
        @start_time: The timestamp of data to start at.
      '''
      df = px.DataFrame(table='http_events', start_time=start_time, end_time=end_time)
      df.failure = df.resp_status >= 400

      df = df[df.remote_addr != '-' or include_unresolved_inbound]
      df = df[df.req_path != '/readyz' or include_ready_checks]
      df = df[df.req_path != '/healthz' or include_health_checks]

      return df

    def inbound_http_summary(df):
      '''Gets a summary of requests inbound to `pod`.

      Equivalent to a single window of `pxviews.inbound_http_latency_timeseries`
      if you aggregate the results of this function by pod.

      Args:
        @df: The DataFrame
      '''

      # Filter only to inbound pod traffic (server-side).
      # Don't include traffic initiated by this pod to an external location.

      df = df.groupby([
        'aria_provider',
        'aria_service',
        'cluster_id',
        'cluster_name',
        'container',
        'deployment',
        'is_cluster_internal',
        'is_cluster_local',
        'is_external',
        'namespace',
        'pod_id',
        'pod_name',
        'pod',
        'remote_addr',
        'requestor_pod',
        'requestor_resolved_hostname',
        'requestor_service',
        'resp_status',
        'responder_resolved_hostname',
        'responder_service',
        'service',
        'upid',
      ]).agg(
        latency_quantiles=('latency', px.quantiles),
        latency_sum=('latency', px.sum),
        num_requests=('time_', px.count),
        stop_time=('time_', px.max),
        num_errors=('failure', px.sum),
      )
      df.time_ = df.stop_time
      df.node = df.ctx['node']
      df.requestor_ip = df.remote_addr

      return df[[
        'aria_provider',
        'aria_service',
        'cluster_id',
        'cluster_name',
        'container',
        'deployment',
        'is_cluster_internal',
        'is_cluster_local',
        'is_external',
        'latency_quantiles',
        'latency_sum',
        'namespace',
        'node',
        'num_errors',
        'num_requests',
        'pod_id',
        'pod_name',
        'pod',
        'remote_addr',
        'requestor_ip',
        'requestor_pod',
        'requestor_resolved_hostname',
        'requestor_service',
        'resp_status',
        'responder_resolved_hostname',
        'responder_service',
        'service',
        'time_',
        'upid',
      ]]

    def exclude_known_remote_addrs(df):
      '''Exclude namespaces which are known to be noise.

      Args:
        @df: The DataFrames to filter.
      '''
      # Exclude DataFrames from the kubelet
      #
      # The kubelet will chat with a cloud providers Instance Metadata Service (IMDS) frequently during normal
      # operation. This is just noise from our perspective, so remove it.
      df = df[df.remote_addr != '169.254.169.254']
      df = df[df.remote_addr != '127.0.0.1']
      df = df[df.remote_addr != '0.0.0.0']

      return df

    df = _http_events(
      start_time=px.plugin.start_time,
      end_time=px.plugin.end_time,
      include_health_checks=False,
      include_ready_checks=False,
      include_unresolved_inbound=False,
    )

    # Filter out entities
    df = exclude_known_remote_addrs(df)

    # Add context
    df.node = df.ctx['node']
    df.container = df.ctx['container_name']
    df.pod = df.ctx['pod']
    df.pod_id = df.ctx['pod_id']
    df.requestor_pod_id = px.ip_to_pod_id(df.remote_addr)
    df.requestor_pod = px.pod_id_to_pod_name(df.requestor_pod_id)
    df.namespace = px.pod_name_to_namespace(df.pod)
    df.requestor_service = px.pod_id_to_service_name(df.requestor_pod_id)

    # The Pod Name, as assigned by Pixie, includes the Pod's namespace in the name. ex. namespace/pod-name.
    # This replace ensures that we only have the pod name
    df.pod_name = px.replace('.*\/', df.ctx['pod'], '')

    df.service = df.ctx['service']
    df.deployment = df.ctx['deployment']
    df.namespace = df.ctx['namespace']
    df.cluster_name = px.vizier_name()
    df.cluster_id = px.vizier_id()
    df.aria_provider = 'Kubernetes'
    df.aria_service = 'Workload'
    df.is_server_side_tracing = df.trace_role == 2

    # Get the traced and remote pod/service/IP information.
    df.traced_pod = df.pod
    df.traced_service = df.service
    df.traced_ip = px.pod_name_to_pod_ip(df.pod)

    localhost_ip_regexp = r'127\.0\.0\.[0-9]+'
    df.is_remote_addr_localhost = px.regex_match(localhost_ip_regexp, df.remote_addr)
    df.remote_pod = px.select(
      df.is_remote_addr_localhost,
      df.pod,
      px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))
    )
    df.remote_service = px.select(
      df.is_remote_addr_localhost,
      df.traced_service,
      px.service_id_to_service_name(px.ip_to_service_id(df.remote_addr))
    )

    df.requestor_ip = px.select(df.is_server_side_tracing, df.remote_addr, df.traced_ip)
    df.responder_ip = px.select(df.is_server_side_tracing, df.traced_ip, df.remote_addr)
    df.requestor_resolved_hostname = px.nslookup(df.requestor_ip)
    df.responder_resolved_hostname = px.nslookup(df.responder_ip)

    # Decorate responder context
    df.responder_pod = px.select(df.is_server_side_tracing, df.traced_pod, df.remote_pod)
    df.responder_pod_id = px.pod_name_to_pod_id(df.responder_pod)
    df.responder_service = px.select(df.is_server_side_tracing, df.traced_service, df.remote_service)
    df.responder_deployment_name = px.pod_id_to_deployment_name(df.responder_pod_id)
    df.responder_node_name = px.pod_id_to_node_name(df.responder_pod_id)
    df.responder_namespace = px.pod_id_to_namespace(df.responder_pod_id)

    # Decorate requestor context
    df.requestor_pod = px.select(df.is_server_side_tracing, df.remote_pod, df.traced_pod)
    df.requestor_pod_id = px.pod_name_to_pod_id(df.requestor_pod)
    df.requestor_service = px.select(df.is_server_side_tracing, df.remote_service, df.traced_service)
    df.requestor_deployment_name = px.pod_id_to_deployment_name(df.requestor_pod_id)
    df.requestor_node_name = px.pod_id_to_node_name(df.requestor_pod_id)
    df.requestor_namespace = px.pod_id_to_namespace(df.requestor_pod_id)

    cluster_local_regexp = r'.+cluster\.local'
    cluster_internal = r'.+internal'

    df.is_cluster_local = px.regex_match(cluster_local_regexp, df.responder_resolved_hostname)
    df.is_cluster_internal = px.regex_match(cluster_internal, df.responder_resolved_hostname)
    df.is_external = (px.ip_to_pod_id(df.responder_ip) == '' and px.ip_to_service_id(df.responder_ip) == '') and (not df.is_cluster_local and not df.is_cluster_internal)

    df = inbound_http_summary(df)

    df = df[df.requestor_pod != ""]

    ip_address_regexp = r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b'
    df.is_ip = px.regex_match(ip_address_regexp, df.responder_resolved_hostname)
    df.responder_resolved_hostname = px.select(
      df.is_ip,
      'UnresolvableIp',
      df.responder_resolved_hostname
    )
    df.remote_addr = px.select(
      df.is_ip,
      'UnresolvableIp',
      df.remote_addr
    )

    ec2_internal_address_regexp = r'ip-[0-9]{1,3}-[0-9]{1,3}-[0-9]{1,3}-[0-9]{1,3}\.ec2\.internal\b'
    df.is_ec2_internal = px.regex_match(ec2_internal_address_regexp, df.responder_resolved_hostname)
    df.responder_resolved_hostname = px.select(
      df.is_ec2_internal,
      'AWSEC2Service',
      df.responder_resolved_hostname
    )

    df = df.groupby([
      'aria_provider',
      'aria_service',
      'cluster_id',
      'cluster_name',
      'container',
      'deployment',
      'is_cluster_internal',
      'is_cluster_local',
      'is_external',
      'latency_quantiles',
      'latency_sum',
      'namespace',
      'pod_name',
      'pod',
      'remote_addr',
      'requestor_pod',
      'requestor_resolved_hostname',
      'requestor_service',
      'resp_status',
      'responder_resolved_hostname',
      'responder_service',
      'service',
    ]).agg(
      http_req_count_in=('num_requests', px.sum),
      http_error_count_in=('num_errors', px.sum),
      http_latency_in=('latency_quantiles', px.any),
      stop_time=('time_', px.max)
    )

    # Compute throughput values.
    window = px.DurationNanos(px.now() - px.parse_time(start_time))
    df.http_req_throughput_in = df.http_req_count_in / window
    df.http_error_throughput_in = df.http_error_count_in / window
    df.http_error_rate_in = px.Percent(
      px.select(
        df.http_req_count_in != 0,
        df.http_error_count_in / df.http_req_count_in,
        0.0,
      )
    )

    df.service = px.replace('\["', df.ctx['service'], '')
    df.service = px.replace('",".*$', df.service, '')
    df.time_ = df.stop_time
    df.p99 = px.pluck_float64(df.latency_quantiles, 'p99')
    df.p90 = px.pluck_float64(df.latency_quantiles, 'p90')
    df.p50 = px.pluck_float64(df.latency_quantiles, 'p50')
    df.lat_sum = px.add(df.latency_sum, 0.0)

    px.export(
      df, px.otel.Data(
        resource={
          # User must specify service_name
          'service.name': "vmware",
          'aria.provider': df.aria_provider,
          'aria.service': df.aria_service,
          'http.dest_hostname': df.responder_resolved_hostname,
          'http.resp_status': df.resp_status,
          'http.source_hostname': df.requestor_resolved_hostname,
          'is_external': df.is_external,
          'kubernetes.cluster.name': df.cluster_name,
          'kubernetes.container.name': df.container,
          'kubernetes.deployment.name': df.deployment,
          'kubernetes.namespace.name': df.namespace,
          'kubernetes.pod.fullname': df.pod,
          'kubernetes.pod.name': df.pod_name,
          'kubernetes.service.name': df.service,
          'kubernetes.service.requestor': df.requestor_service,
          'kubernetes.service.responder': df.responder_service,
          'px.cluster.id': df.cluster_id,
          'remote_addr': df.remote_addr,
          'service.instance.id': df.pod,
        },
        data=[
          px.otel.metric.Summary(
            name='kubernetes.http_events.latency_ns',
            description='Latency of the request/response',
            count=df.http_req_count_in,
            sum=df.lat_sum,
            quantile_values={
              0.99: df.p99,
              0.90: df.p90,
              0.50: df.p50,
            },
            attributes={},
          ),
          px.otel.metric.Gauge(
            name='kubernetes.http_events.reqs_per_second',
            description='Current number of requests per second',
            value=df.http_req_throughput_in,
            unit="req/s",
            attributes={},
          ),
          px.otel.metric.Gauge(
            name='kubernetes.http_events.err_per_second',
            description='Current number of errors per second',
            value=df.http_error_throughput_in,
            unit="err/s",
            attributes={},
          ),
          px.otel.metric.Gauge(
            name='kubernetes.http_events.err_percentage',
            description='Current percentage of errors',
            value=df.http_error_rate_in,
            unit="%",
            attributes={},
          )
        ],
      ),
    )
  configs.yaml: |
    otelEndpointConfig:
      insecure: true
      url: aria-telegraf-collector.observability-system.svc.cluster.local:4317
  cron.yaml: |
    frequency_s: 10