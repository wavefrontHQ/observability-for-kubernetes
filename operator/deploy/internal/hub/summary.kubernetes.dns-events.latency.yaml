---
apiVersion: v1
kind: ConfigMap
metadata:
  name: summary.kubernetes.dns-events.latency
  namespace: observability-system
  ownerReferences:
  - apiVersion: apps/v1
    kind: Deployment
    name: wavefront-controller-manager
    uid: '{{ .ControllerManagerUID }}'
  labels:
    purpose: cron-script
    app.kubernetes.io/name: wavefront
    app.kubernetes.io/component: hub
data:
  script.pxl: |
    '''DNS Overview Map

    Shows summary DNS requests in the cluster, with some latency information.
    '''

    import px

    def exclude_known_namespaces(df):
      '''Exclude namespaces which are known to be noise.

      Args:
        @df: The DataFrames to filter.
      '''

      # Exclude DataFrames from kube-system
      #
      # It is not useful to see metrics related to the functioning of Kubernetes' system-components (such as the CNI,
      # core-dns, aws-node, etc)
      df = df[df.ctx['namespace'] != 'kube-system']

      # Exclude DataFrames from pixie client-side resources
      #
      # We do not need to know service-to-service communication happening between and amongst the pixie components
      # themselves, so we exclude them.
      df = df[df.ctx['namespace'] != 'pl']
      df = df[df.ctx['namespace'] != 'px-operator']
      df = df[df.ctx['namespace'] != 'olm']

      # Exclude DataFrames from aria-k8s
      #
      # This namespace is where the k8s-collector and telegraf-collector live. Excluding this namespace ensures that
      # data sent to Lemans from telegraf will not be re-reported by Pixie (since sending to Lemans happens over HTTP(s)
      df = df[df.ctx['namespace'] != 'aria-k8s']

      # Exclude DataFrames from observability-system
      #
      # This namespace is where the k8s-collector and telegraf-collector (as deployed by the Wavefront operator) live.
      # Excluding this namespace ensures that data sent to Lemans from telegraf will not be re-reported by Pixie (since
      # sending to Lemans happens over HTTP(s)
      df = df[df.ctx['namespace'] != 'observability-system']

      return df

    def exclude_known_remote_addrs(df):
      '''Exclude namespaces which are known to be noise.

      Args:
        @sdf: The DataFrames to filter.
      '''
      # Exclude DataFrames from the kubelet
      #
      # The kubelet will chat with a cloud providers Instance Metadata Service (IMDS) frequently during normal
      # operation. This is just noise from our perspective, so remove it.
      df = df[df.remote_addr != '169.254.169.254']

      return df

    # kube-dns.kube-system.svc.cluster.local -> kube-dns.kube-system
    def format_nslookup_name(df):
      df.idx1 = px.find(df.to_entity, '.svc.cluster')
      leftovers = df[df.idx1 < 0]
      df = df[df.idx1 >= 0]
      df.to_entity = px.substring(df.to_entity, 0, df.idx1)
      return df.append(leftovers)

    def dns_flow_graph(start_time, end_time):
      df = px.DataFrame('dns_events', start_time=start_time, end_time=end_time)

      # Filter out entities
      df = exclude_known_namespaces(df)
      df = exclude_known_remote_addrs(df)

      df.service = px.replace('\["', df.ctx['service'], '')
      df.service = px.replace('",".*$', df.service, '')

      # Client-side tracing only.
      df = df[df.trace_role == 1]
      df = df.drop(['trace_role'])

      # Add context.
      df.pod = df.ctx['pod']
      df.service = df.ctx['service']
      df.namespace = df.ctx['namespace']

      # Filter nodes for graph.
      df = df[not px.contains(df.pod, "pl")]
      df = df[not df.pod == ""]
      df = df[not df.remote_addr == "-"]

      # Specify from and to entities.
      df.from_entity = df.pod

      localhost_ip_regexp = r'127\.0\.0\.[0-9]+'
      df.is_remote_addr_localhost = px.regex_match(localhost_ip_regexp, df.remote_addr)
      df.to_entity = px.select(
        df.is_remote_addr_localhost,
        px.upid_to_pod_name(df.upid),
        px.Service(px.nslookup(df.remote_addr))
      )

      # Add context
      df.node = df.ctx['node']
      df.container = df.ctx['container_name']
      df.pod = df.ctx['pod']
      df.pod_id = df.ctx['pod_id']
      df.requestor_pod_id = px.ip_to_pod_id(df.remote_addr)
      df.requestor_pod = px.pod_id_to_pod_name(df.requestor_pod_id)
      df.namespace = px.pod_name_to_namespace(df.pod)
      df.requestor_service = px.pod_id_to_service_name(df.requestor_pod_id)

      # The Pod Name, as assigned by Pixie, includes the Pod's namespace in the name. ex. namespace/pod-name.
      # This replace ensures that we only have the pod name
      df.pod_name = px.replace('.*\/', df.ctx['pod'], '')

      df.service = df.ctx['service']
      df.deployment = df.ctx['deployment']
      df.namespace = df.ctx['namespace']
      df.cluster_name = px.vizier_name()
      df.cluster_id = px.vizier_id()
      df.aria_provider = 'Kubernetes'
      df.aria_service = 'Workload'
      df.is_server_side_tracing = True

      # Get the traced and remote pod/service/IP information.
      df.traced_pod = df.pod
      df.traced_service = df.service
      df.traced_ip = px.pod_name_to_pod_ip(df.pod)

      localhost_ip_regexp = r'127\.0\.0\.[0-9]+'
      df.is_remote_addr_localhost = px.regex_match(localhost_ip_regexp, df.remote_addr)
      df.remote_pod = px.select(
        df.is_remote_addr_localhost,
        df.pod,
        px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))
      )
      df.remote_service = px.select(
        df.is_remote_addr_localhost,
        df.traced_service,
        px.service_id_to_service_name(px.ip_to_service_id(df.remote_addr))
      )

      df.requestor_ip = px.select(df.is_server_side_tracing, df.remote_addr, df.traced_ip)
      df.responder_ip = px.select(df.is_server_side_tracing, df.traced_ip, df.remote_addr)
      df.requestor_resolved_hostname = px.nslookup(df.requestor_ip)
      df.responder_resolved_hostname = px.nslookup(df.responder_ip)

      # Decorate responder context
      df.responder_pod = px.select(df.is_server_side_tracing, df.traced_pod, df.remote_pod)
      df.responder_pod_id = px.pod_name_to_pod_id(df.responder_pod)
      df.responder_service = px.select(df.is_server_side_tracing, df.traced_service, df.remote_service)
      df.responder_deployment_name = px.pod_id_to_deployment_name(df.responder_pod_id)
      df.responder_node_name = px.pod_id_to_node_name(df.responder_pod_id)
      df.responder_namespace = px.pod_id_to_namespace(df.responder_pod_id)

      # Decorate requestor context
      df.requestor_pod = px.select(df.is_server_side_tracing, df.remote_pod, df.traced_pod)
      df.requestor_pod_id = px.pod_name_to_pod_id(df.requestor_pod)
      df.requestor_service = px.select(df.is_server_side_tracing, df.remote_service, df.traced_service)
      df.requestor_deployment_name = px.pod_id_to_deployment_name(df.requestor_pod_id)
      df.requestor_node_name = px.pod_id_to_node_name(df.requestor_pod_id)
      df.requestor_namespace = px.pod_id_to_namespace(df.requestor_pod_id)

      # Reformat to_entity and from_entity for consistency between pods and services.
      df = format_nslookup_name(df)

      # Aggregate the connections.
      df = df.groupby([
        'aria_provider',
        'aria_service',
        'cluster_id',
        'cluster_name',
        'container',
        'deployment',
        'namespace',
        'pod_id',
        'pod_name',
        'pod',
        'remote_addr',
        'requestor_pod',
        'requestor_resolved_hostname',
        'requestor_service',
        'responder_resolved_hostname',
        'service',
        'upid']).agg(
          latency_quantiles=('latency', px.quantiles),
          latency_sum=('latency', px.sum),
          num_requests=('time_', px.count),
          stop_time=('time_', px.max),
          count=('latency', px.count)
      )

      return df

    df = dns_flow_graph(
      start_time=px.plugin.start_time,
      end_time=px.plugin.end_time,
    )
    df.time_ = df.stop_time
    df.p99 = px.pluck_float64(df.latency_quantiles, 'p99')
    df.p90 = px.pluck_float64(df.latency_quantiles, 'p90')
    df.p50 = px.pluck_float64(df.latency_quantiles, 'p50')
    df.lat_sum = px.add(df.latency_sum, 0.0)

    px.export(
      df, px.otel.Data(
        resource={
          # User must specify service_name
          'service.name': "vmware",
          'aria.provider': df.aria_provider,
          'aria.service': df.aria_service,
          'dest_hostname': df.responder_resolved_hostname,
          'kubernetes.cluster.name': df.cluster_name,
          'kubernetes.container.name': df.container,
          'kubernetes.deployment.name': df.deployment,
          'kubernetes.namespace.name': df.namespace,
          'kubernetes.pod.fullname': df.pod,
          'kubernetes.pod.name': df.pod_name,
          'kubernetes.service.name': df.service,
          'px.cluster.id': df.cluster_id,
          'remote_addr': df.remote_addr,
          'service.instance.id': df.pod,
          'source_hostname': df.requestor_resolved_hostname,
        },
        data=[
          px.otel.metric.Summary(
            name='kubernetes.dns_events.latency_ns',
            description='Latency of the dns request/response in nanos',
            count=df.num_requests,
            sum=df.lat_sum,
            quantile_values={
              0.99: df.p99,
              0.90: df.p90,
              0.50: df.p50,
            },
            attributes={},
          ),
        ],
      ),
    )
  configs.yaml: |
    otelEndpointConfig:
      insecure: true
      url: aria-telegraf-collector.aria-k8s.svc.cluster.local:4317
  cron.yaml: |
    frequency_s: 60